#summary Data Mining : The Missing Link in Empirical Software Engineering

<wiki:toc max_depth="4" />

|| <img align=right src="http://www.ksu.edu.sa/sites/Colleges/AppliedMedicalSciences/PublishingImages/under-construction.jpg" width=200>|| *NOTE: This draft is not yet released.*||


= Abstract =

We distinguish "theories" (which are "true" in some global sense) from 
"models" (which may not be "true", be are useful for some local task).
Software engineering research rarely produces externally valid theories.
There are so very few examples of generalizable theories,
despite there being so many examples of research groups trying to find them.
To illustrate this point, we offer examples of these failures-to-generalize from the fields of:
 * design of programming languages
 * software metrics definitions
 * and other SE domains, as well.

Even if SE can't generate theories, we can still find useful local models.  Data mining
is a rich area of research that has generated long lists of methods that are simple to code and, usually, generate
effective models.  This talk will offer:
 * Examples of those local conclusions (as applied to software defect prediction), as well as
 * Catalogs of data mining methods that are simplest and fastest to apply, while often generating useful insights.

Advocating the generation of local models, that usually do not generalize to theories, runs counter to the positivist
tradition of scientific development.  A detailed look of the mechanics of data mining will highlight the difficulty
in producing generalizable theories. 

I am not the first to argue that this tradition is sterile- but I
do not think that the SE culture fully acknowledges the failure of that approach.  If we did, then we would
augment current methods with:
 * studies on _stochastic stability_;
 * _noise reduction operators_, to remove spurious signals;
 * _anomaly detectors_. for determining when a model has gone "out of scope";
 * automatic model _repair tools_, to learn new models when the old ones are no longer relevant
 
The lesson on data mining is that while nothing is "true", many more things are "false".
While multiple models can be generted from the available data, many models are unsupported by any data.
Now the good news is that the space of possible models smaller than you might thing. XXX
Rather, it is a claim that we still critically 
it turns out that there are general theories about finding locally useful models.  
To illustrate this point, this talk will:
 * Discusses one such method from case-based reasoning, as applied to software effort estimation.

My conclusion will be that:
 * While we should strive to build general theories of software engineering, 
 * We should not be surprised or discouraged if we fail to do so. 

More generally, rather than try to "clean up" empirical software engineering with more rigorous methods, we should
instead explore methods for the faster generation and assessment of local models.

_About the speaker_ Dr. Tim Menzies (tim@menzies.us) has been working on advanced modeling and AI since 1986. He received his PhD from the University of New South Wales, Sydney, Australia and is the author of over 164 refereed papers.
A former research chair for NASA, Dr. Menzies is now a associate professor at the West Virginia University's Lane Department of Computer Science and Electrical Engineering.
For more information, visit his web page at http://menzies.us.

= Introduction =

Remember of the old joke?

http://ourmine.googlecode.com/svn/trunk/share/img/thenAMiracle.jpg

If you read the empirical SE literature, you can find a similar "missing link" in 
[#Easterbrook07 recent descriptions of how to conduct empirical SE studies]:
  * 3 pages: research questions
  * 2 pages: different forms of "empirical truth"
  * 1 page: role of theory building
  * 9 pages: selecting methods
  * 1 page: data collection techniques
  * 0 pages: data analysis (and then a miracle happens)
  * 2 pages: empirical validity
  * 1 page: conclusions

Speaking as a data mining researcher, I'm here to say that selecting _data analysis_ methods deserves more than 0 pages:

 * There are [http://promisedata.org/2010/ entire conferences] devoted to just "data analysis";
 * A detailed study of "data analysis" reveals:
   * Data analysis may never produce generalizable SE theories 
     * Shock! Horror!
     * (And if such generalizations exist, shouldn't we have found them by now?)
 * Methods of "data analysis" are close to methods of "control"
   * So "empirical methods" becomes "how to control a project".

----
<img align=right src="http://ourmine.googlecode.com/svn/trunk/share/img/death2powerpoint.png">
= Why Aren't we Looking at Powerpoint? =


Like many before me, ([#Tufte05], [#Tufte06]),
I distrust Powerpoint:
 * Powerpoint is a tool for a one-way broadcast of completed ideas 
 * Knowledge diamonds;
 * Dressed to impress.

This format is faster to write.
 * Faster to hyperlink to references
 * You can write comments on this material, below.

Anyway,  this talk comes from a different intellectual tradition:
 * Knowledge relativism
   * Using the hammer changes the hammer.

Seems inappropriate to dress it up in Powerpoint

<br><br>
<br><br>
<br><br>
<br><br>
<br><br>
<br><br>
<br><br>
----
= The Current (Poor) State of Empirical AI =

{{{
From: Tim Menzies
To:   David Budgen
Date: Mon, Sep 7, 2009 at 10:19 AM

This question may sound somewhat abrupt (even, rude) to you, so I
preface it with:

- Your CSEET talk completely turned my thinking around. I think about
  it more than anything else i've seen in the last decade.

- I am a strong advocate of ebse and, where possible, I support its
  goals (e.g. I made structured abstract mandatory for PROMISE 2010)

Anyway, here's my question (about empirical SE):

- Where are the results?

Thanks!
t
}}}
Some prominent examples where initial attempts to clarify empirical SE did not produce results.

== Example1:   Fenton's famous book on [#Fenton98 Software Metrics] ==

 * Fenton, 2007: "... much of the current software metrics research is inherently irrelevant to the 
   industrial mix ..... any software metrics program that depends on some extensive metrics collection is doomed to failure ...".
 * Now, he builds Bayesian models based on expert intutions.

== Example2: how best to assess software written at another site? ==
 * This is the _Independent V&V_ task
 * Over a hundred tasks proposed by different authors for IV&V.
 * At NASA, from 2005 to 2007, the list was as follows.
 * In 2007, I found [#Menzies07a very few attempts] to assess the relative cost-benefits of these tasks. 

{{{
phase           wbs                                     factor   RANK  
--------------  ---    ---------------------------------------   ---- 
concept         2.1                             Reuse Analysis   11
                2.2           Software Architecture Assessment    9
                2.3                 System Requirements Review   10
                2.4                Concept Document Evaluation    8
                2.5   SW/User Requirements Allocation Analysis    6
                2.6                      Traceability Analysis    7
--------------  ---    ---------------------------------------    
requirements    3.1      Traceability Analysis -  Requirements    4
                3.2           Software Requirements Evaluation    5
                3.3          Interface Analysis - Requirements    3
                3.4                  System Test Plan Analysis    2
                3.5              Acceptance Test Plan Analysis    1   <====
                3.6                 Timing and Sizing Analysis        ?
--------------  ---    ---------------------------------------    
design          4.1             Traceability Analysis - Design   16 
                4.2                 Software Design Evaluation   15 
                4.3                Interface Analysis - Design   14 
                4.4                 Software FQT Plan Analysis   17 
                4.5    Software Integration Test Plan Analysis   12 
                4.6                          Database Analysis   13
                4.7               Component Test Plan Analysis        ?
--------------  ---    ---------------------------------------    
implementation  5.1               Traceability Analysis - Code   22 
                5.2   Source Code and Documentation Evaluation   23 
                5.3                  Interface Analysis - Code   21 
                5.4                  System Test Case Analysis   19 
                5.5                 Software FQT Case Analysis   20 
                5.6          SW Integration Test Case Analysis        ?
                5.7              Acceptance Test Case Analysis        ?
                5.8     SW Integration Test Procedure Analysis        ?
                5.9       SW Integration Test Results Analysis        ?
                5.10              Component Test Case Analysis        ?
                5.11            System Test Procedure Analysis   18 
                5.12           Software FQT Procedure Analysis        ?
--------------  ----   ---------------------------------------    
test            6.1               Traceability Analysis - Test   27 
                6.2                   Regression Test Analysis        ?
                6.3                        Simulation Analysis   25 
                6.4               System Test Results Analysis   24 
                6.5              Software FQT Results Analysis   26 
--------------  ---    ---------------------------------------    
other           7.1             Operating Procedure Evaluation        ?
                7.2                         Anomaly Evaluation        ?
                7.3                       Migration Assessment        ?
                7.4                      Retirement Assessment        ?
}}}

(BTW, the numbers on the RHS show the result of a six month study with some NASA civil servants who performed
several pieces of magic with their databases. Rankings are based on how many high severity issues were found
using the least cost. For more details, see [#Menzies07a:w
 here]).

== Example3: What is the Best Computer Programming Language? ==

No termination on that debate; increased diversity in that conclusion, as time goes by:

http://unbox.org/wisp/var/timm/09/310/share/img/tiobe-index.png












 
see, i recently had to review an IEEE standard on IV&V. 83 supposedly
"best practices" and i could only find empirical evidence  comment on
just a handful of those practices.

Effort estimation research has made
some
excellent attempts at recording those best practices 
[#Jørgensen04 Jørgensen04]  [#]Kitchenham07 Kitchenham07]:
but even those do not offer clear guidelines:
 * [#Jørgensen04 Jørgensen04] reports that expert estimates are better/worse/same as model estimates in5/5/5 reported cases studies
 * [#]Kitchenham07 Kitchenham07]: reports that the jury is out on the value of using local vs imported data for building estimates.

Is SE is so diverse, so fundamentally weird, that:
* there are no "general principles". 

What i suspect is that the are not general SE
principles:
 *  but there might be general methods for finding the local



Mon, Sep 7, 2009 at 10:19 AM
= References =

== Easterbrook07 ==

Easterbrook, S. M., Singer, J., Storey, M, and Damian, D. Selecting Empirical Methods for Software Engineering Research. Appears in F. Shull and J. Singer (eds) "Guide to Advanced Empirical Software Engineering", Springer, 2007.
http://www.cs.toronto.edu/~sme/papers/2007/SelectingEmpiricalMethods.pdf

== Fenton98 ==

Software Metrics: A Rigorous Approach 
by Norman E. Fenton, Shari Lawrence Pfleeger.
PWS, 1998 (second edition).


== Jørgensen04 =

“A Review of Studies on Expert Estimation of Software
M. Jørgensen, “A Review of Studies on Expert Estimation of Software
Development Effort,” J. Systems and Software, vol. 70, nos. 1–2, 2004,
pp.  37–60;

== Kitchenham07 ==

B.A. Kitchenham, E. Mendes, and G.H. Travassos Cross versus
Within-Company Cost Estimation Studies: A Systematic Review,  IEEE
Transactions on Software Engineering archive Volume 33 , Issue 5
May 2007, Pages 316-329

== Menzies07a ==
"Learning Better IV&V Practices" by T. Menzies and M. Benson and K. Costello and C. Moats and M. Northey and J. Richarson. Innovations in Systems and Software Engineering March 2008 . Available from http://menzies.us/pdf/07ivv.pdf. 

== Tufte05 ==

Tufte, E. Powerpoint Does Rocket Science--and Better Techniques for Technical Reports.  September 6, 2005.
http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001yB&topic_id=1&topic=Ask+E.T.

== Tufte06 ==
Tufte, E. The Cognitive Style of Powerpoint: Pitching Out Corrupts Within, 2006.
http://www.edwardtufte.com/tufte/books_pp
