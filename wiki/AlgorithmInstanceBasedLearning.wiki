#summary reasoning using raisin bread

= Introduction =
<img width=250 align=right src="http://ourmine.googlecode.com/svn/trunk/share/img/raisinBread.jpg">
Instance-based methods don't _think_, they don't build models from data. Instead, they take new things and float them nearest the older things. And what we decide about the new thing is taken from the older things in the local neighborhood.

Think about the training data as raisins in a  loaf of bread (the analogy isn't perfect: raisin bread is  3-dimensional object and a data set with N columns forms an N-dimensional object).

{{{
dev_mode,   rely   ,data   ,cplx  ... ,loc ,time2Develop
========    ====    ====    ====       ===  ============
embedded,   0.75   ,0.94   ,1.3   ... , 13   ,82
embedded,   0.88   ,1.16   ,0.7,  ... ,113 ,2040
embedded,   0.88   ,1.16   ,0.85, ... ,293 ,1600
embedded,   0.94   ,1      ,0.85, ... , 48 , 387
embedded,   1      ,1.16   ,1.15, ... ,252 ,2455
embedded,   1.15   ,0.94   ,1.3,      , 22 ,1075
}}}

= How to find your nearest raisin? =

Euclidean distance :

    * sqrt( (x2-x1)<sup>2</sup> + (y2-y1)<sup>2</sup> + ... )
    * for non-numerics:
          * distance = 0 if the same
          * distance = 1 if different
    *  normalize: replace X with (X - MinX)/(MaxX - MinX).
    *  distort some dimensions if they are more important that others

Squared Euclidean :

    * Place progressively greater weight on objects that are further apart.

City-block (Manhattan) :

    * Average difference across dimensions.
         * sum(abs(x2 - x1) + abs(y2 - y1) + ..)
    * Usually, same results as Euclidean
          * But dampens effect of single large differences (outliers) is dampened

Chebychev distance :

    * Maximum(abs(x2 - x1) + abs(y2 - y1) + ..)
    * Things are "different" if they are different on any dimensions.

= Example (sorting out the Raisins) =

Find the nearest neighbor of the training data. Build one "pretend" instance half-way between each instance:

  * For numeric data, half-way is (x1-x2)/2, (y1-y2)/2, etc
  * For all the discrete columns with different values, flip half of them (picked at random) to the value in the other instance.

<img width=350 align=right src="http://ourmine.googlecode.com/svn/trunk/share/img/Binary_tree.png">

Now repeat to form a binary tree whose leaves (in green) are the real data and the rest is made-up stuff. This is called GAC: _Greedy Agglomerative Clustering_. Warning: it is very slow.

Premise of instance-based learning is that it is local neighborhoods are _better_ than casting a wider net. In terms of recursively descending the tree, this premise is true if the variance of sub-trees is less than the super tree.

  * variance: <img src="http://upload.wikimedia.org/math/6/c/8/6c84cac9b183bb78e05fb51205f7f7a0.png">
  * variance of a sub-tree: go to the instances in the leaves and compute the variance of their output variable.
  * weighted variance beneath a node: give three subtrees containing N=N1+N2+N3 leaf nodes with variance V1,V2,V3 then the weighted variance is 
       * {{{ V1*N1/N + V2*N2/N + V3*N3/N }}}

To make a prediction, take a test instance 
 *  move it to the sub-tree with the closest root. 
 * stop descending when 
     * the size of the sub-tree is "k" (some fixed constant)
     * the weighted-variance of the subtree is greater than the current tree
 * After stopping, return the median performance statistic of the leaves in the sub-tree.

How big should "k" be?
 * k = 10
 * k = sqrt(leaf nodes)
 * try k = 1 to size of tree and use the k that has the smaller error
 * irrelevant if stopping using weighted sub-tree variance.
 * and it doesn't matter (in the results below, nearly the same behavior for k=2,4,8,16

= Trust (what raisins are hard to swallow?) =

Nice features of this approach
 * In some data sets, there is a relationship between prediction error and variance of the performance statistic in the sub-tree
 * So we can return not just the estimate, but an _trust_ measure of how much we should believe that estimate.

In the following experiments, 20 times, we took out one training instance, GAC the remaining, then estimated the set-aside. Note that after some critical value of variance (on the x-axis), the error spikes (on the y-axis). So, if your test instance falls into sub-trees with that variance, *do not trust the estimate*.

E.g. [http://promisedata.org/repository/data/coc81/coc81_1_1.arff Coc81]:

 * x-axis: weighted variance of sub-tree
 * y-axis: log of error = magnitude of relative error = abs(actual - predicted)/ actual


<img width=500 align=center src="http://ourmine.googlecode.com/svn/trunk/share/img/coc81mreVar.jpg">



[http://promisedata.org/repository/data/nasa93/nasa93.arff Nasa93]

 * x-axis: weighted variance of sub-tree
 * y-axis: log of error = magnitude of relative error = abs(actual - predicted)/ actual


<img width=500 align=center src="http://ourmine.googlecode.com/svn/trunk/share/img/nasa93mreVar.jpg">

[http://promisedata.org/repository/data/desharnais/desharnais_1_1.arff Desharnis]

 * x-axis: weighted variance of sub-tree
 * y-axis: log of error = magnitude of relative error = abs(actual - predicted)/ actual

<img width=600 align=center src="http://ourmine.googlecode.com/svn/trunk/share/img/desharnaisMreVar.jpg">