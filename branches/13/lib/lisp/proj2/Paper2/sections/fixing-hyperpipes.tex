\subsection{Introducing MultiPipes}
We saw incredible potential in HyperPipes if we could reign in
the issues described above. One of the major advantages of HyperPipes
is its ability to classify a single row very fast. The Pipes 
condition can be stored and retrieved at a later time for 
classification unlike some other learners whose classification 
relies heavily on the actual contents of previous rows. Below we 
describe how HyperPipes was transformed into MultiPipes.


\subsection{Fixing Tied Classes}
When it was discovered that HyperPipes tended to choose classes 
towards the end of the classes list we investigated further to 
find that many classes were tieing against other classes. We 
then decided that this was unacceptable. Overwriting a class 
with another class of the same score puts a large emphasis on 
the order in which you score the classes. For this issue we 
decided to temporarily throw away the idea of classification 
and modified the code to return any classes who tied. This 
simple modification proved to us that this issue alone was a 
major factor in HyperPipes demise when put up against other 
classifiers. To recap the original hyperpipes said that if 
the current score is equal to or greater than the best score 
set the best class to the current class. After modification 
hyperpipes now states that if the score is greater than the 
best score set the best class to an array containing only the 
current class. If the current score is equal to the best score 
then append the current class to the list of best classes.


\subsection{Fixing Over Fitting}
As described previously Hyperpipes has an over fitting issue 
when it learns too much. While we have no implemented these 
potential fixes our possible solutions are described below:
\begin{enumerate}
\item Limit Number of Rows To Be Learned: 
	It might be effective to simply limit the number of rows 
	that HyperPipes will use when doing its learning. This 
	number of rows might be calculated based on the number 
	classes and it may also require that this limit be 
	evenly distributed across all classes.
\item Detect Overfitting by Class Overlap:
	It may be possible to detect over-fitting by determining 
	the amount of overlap between classes. In other words, 
	if the number of attributes in a HyperPipe reaches a 
	certain level we could say that we should not modify our 
	HyperPipes with the information learned in this new line
	as it would cause too much overlap between classes.
\end{enumerate}


\subsection{Fixing Outliers}
We have implemented some fixes to the problem of outliers. 
However, there are many other outlier fixing strategies that have 
not been implemented. Below is a list of our outlier fixing 
strategies and thier implemtation status:
\begin{enumerate}
\item Weighted Means: This fix has been implemented. What this fix 
does is it changes the scoring mechanism. In the pseudocode for 
Classify (Program \ref{pro:Classify}) you will notice that it returns 1 if the current attribute 
value falls within the range of that given by the HyperPipe for that 
Attribute. The Weighted Means changes the 1 to a number between 0 
and 1 which represents the distance from the mean within the range. 
Two versions of this are explained further in Section 5.
\item Outlier Detection Algorithm: This fix has been implemented. 
Every time HyperPipes attempts to add experience to its numerical bounds
the algorithm calculates the z-score\cite{Larsen01} for the value attempting to be added. 
If the Z-Score is greater than 1.96 then the value is not used to expand
the ranges within the hyperpipe.
\item Slowly Changing Ranges: This fix has been implemented. 
The same fix we used in the outlier detection algorithm also allows for 
slowly changing ranges. Its important to realize that the value being
considered is added to the stastics for consideration in the z-score 
calculation and its addition to the statistics is not reversed if the
value is determined to be an outlier. This means that if the value 
determined to be an outlier occurs multiple times it is likely that 
it will eventually receive a z-score less than 1.96 and no longer be
considered an outlier and will subsequently be added to the min and max
for the hyperpipe.
\end{enumerate}


\subsection{Fixing Memory Management}
As explained above the old HyperPipes implementation needs information 
on the entire dataset for intialization. We saw value in making 
HyperPipes work on an ever changing stream of data. We implemented this 
by intializing our set of HyperPipes to an empty array. As new classes 
are discovered a new HyperPipe is created for that class and appended 
to the HyperPipes array. This allows us to use a straight datafile with 
just columns of data and no header information. 
