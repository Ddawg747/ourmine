% This is "sig-alternate.tex" V1.9 April 2009
% This file should be compiled with V2.4 of "sig-alternate.cls" April 2009
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.4 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.4) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2009} %will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V1.9 - April 2009

\documentclass{sig-alternate}

\begin{document}
%
% --- Author Metadata here ---
%\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (200X) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{General models for defect prediction?}
\subtitle{[progress report]}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Lonnie Bowe
%\titlenote{CS grad}
\\
       \affaddr{West Virginia University}\\
%       \affaddr{1932 Wallamaloo Lane}\\
%       \affaddr{Wallamaloo, New Zealand}\\
       \email{lbowe@csee.wvu.edu}
\alignauthor
Aglika Gyaourova \\
       \affaddr{West Virginia University}\\
       \email{agyaouro@csee.wvu.edu}\\
\alignauthor
Zack Hutzell\\
       \affaddr{West Virginia University}\\
       \email{zhutzell@csee.wvu.edu}\\
}

\maketitle
\begin{abstract}
\end {abstract}

\keywords{defect predictors, static attributes, general model}

\section{Introduction}
\section{Databases}


\section{Methods}
Our goal is to find a general model for defect predictors. For this purpose, the experiments are divided
into  within company (WC) and cross-company (CC). For the WC experiments, 90\% of one data set
is used for training the classifier and the rest 10\% for evaluating the classifier performance. This process
is repeated 10 times, by randomly selecting the instances to be used for evaluation.

In all data sets, the distribution of the instances from the two classes, i.e. the defect and the non-defect, is
imbalanced. The defect class is represented by a smaller number of instances ranging  from 0.4\% to 32\% of
all instances in different data set~\cite{Turhan2009}. During training the number of instances of the non-defect
class was reduced to the number of instances in the defect class by random deletion.

The Bayes classifier finds a decision that minimizes the Bayes error among classes. This is the theoretically
optimal classifier when the attribute values of each class classes have a normal probability distribution. The
Bayes classifier operates using the posterior probabilities of the classes as defined by the Bayes' theorem. In a
two class problem having only a single attribute, the classifier decision is the attribute value at which the
posterior probability of one of the classes becomes larger than the posterior probability of the other class. The
naive Bayes classifier assumes independent attributes. Practice in software engineering has shown that this
classifier performs well even when its assumptions are not met.
\begin{figure*}[tbp]
\makebox[\linewidth]{\hrulefill}
{\tt\small
\begin{verbatim}
naive-bayes-classify(instance train)
  k = 1
  m = 2
  classification = null
  classification_score = inf
  for each class in classes(train)
    prior_probability=(k+get_class_count(train, class))/(length(train)+(k*(length(classes(train)))))
    sum = 0
    for each feature in row
      if(!class_column(feature) && !unknown_feature(feature))
        sum = sum + (class_frequency(feature, class, train)
        						         + (m * prior_probability)) / (length(get_class_count(train class)) + m)
    if(sum > classification_score)
      classification = class
  return classification
\end{verbatim}}
\makebox[\linewidth]{\hrulefill}
\caption{Naive Bayes classifier on categorical data.}
\label{fig:naiveBayes}
\end{figure*}

Applying naive Bayes on categorical (discrete) data is fast and easy. In this case the naive Bayes operates on the
conditional frequencies of the categorical values~\ref{fig:naiveBayes}. Since discretization of continuous
attributed does not have significant effect on the performance~\cite{Dougherty95}, we mapped the attribute
values into a discrete range before running the learner. A discretization method that accounts for the distribution
of the values is the equal frequency discretization.  This method splits a list of numbers into a predefined
number of intervals, such that every interval contains the equal count of list elements,
figure~\ref{fig:discretization}.
\begin{figure}[tbp]
\makebox[\linewidth]{\hrulefill}
{\tt\small
\begin{verbatim}
equal-frequency-discretizer(dataset, bins)
  for each column in dataset
    //sort the values in the column
    sort(dataset, column)
    for each value in the current column
      //change each value to its discretized replacement
      value=min(n-1, floor((value/(length(column)-1))*bins))
\end{verbatim}}
\makebox[\linewidth]{\hrulefill}
\caption{Equal frequency discretization.}
\label{fig:discretization}
\end{figure}

Another discretization method, {\tt Nbins}, creates intervals whose value ranges have equal width,
figure~\ref{fig:nbins}.
\begin{figure}[tbp]
\makebox[\linewidth]{\hrulefill}
{\tt\small
\begin{verbatim}
equal-width-discretizer(set, bins)
    minval=min(set)
    maxval=max(set)
    for each value in set
      //find the interval in which the value belongs
      //merge the last two intervals
      value=min(nbins,
                floor((value-minval)/(maxval-minval)*nbins))
\end{verbatim}}
\makebox[\linewidth]{\hrulefill}
\caption{Equal width discretization ({\tt Nbins}).}
\label{fig:discretization}
\end{figure}

\section{Experiments}
We performed experiments on cross-project, within company data using the sets {\tt ar3}, {\tt ar4}, and {\tt
ar5}. The learner was naive Bayes and data was preprocessed using equal frequency discretization. Deletion of
rows was used to obtain an equal number of instances in the two classes. Thus, the prior probabilities of the
classes are the same. Equal priors may be an appropriate assumption and this is one way to achieve it for data
having a large sample bias. Instances from the over-represented class were deleted at random before training
the classifier.
%\begin{center}
%\fbox{
%\parbox{.96\linewidth}{
%ala-bala }}
%\end{center}

\subsection{Performance evaluation}
To evaluate the performance of the learned model we used the accuracy, recall, and precision measures, defined
by:
%\begin{equation}
\begin{align}
accuracy &= (A+D)/(A+B+C+D) \nonumber \\
precision &= D/(C+D)\\
recall &= D/(B+D)~, \nonumber
\end{align}
%\end{equation}
where A, B, C, and D are the true negatives, false negatives, false positives, and true positives respectively. The
accuracy gives the portion of correct decision over all classes. The precision is the portion of true positives from
all instances predicted as a given class and the recall is the portion of true positives from all instances belonging
to a given class. All these measures have a range between 0 and 1, with 1 being the best score.

\subsection{Results}
\begin{figure}[tbp]
\begin{center}
\includegraphics[width=.99\linewidth]{pics/accuracy.eps}
\caption{Accuracy for the ar* data sets using cross-project data.}
\label{fig:accuracy}
\end{center}
\end{figure}
The accuracy of performance degrade when using cross-project data compared to within project data and the
original data sets, figure~\ref{fig:accuracy} and figure~\ref{fig:accuBase}. However, when the training data was
subsampled to equal priors there was significant improvement in performance when training on the {\tt ar3} set
and testing on the {\tt ar5} set. Moreover, the performance did not degrade when moving from within project to
cross project experiments. This suggests, that subsampling gives a more accurate  estimation for the
performance of a model in a cross-project prediction.
\begin{figure}[tbp]
\begin{center}
\includegraphics[width=.99\linewidth]{pics/accuracyBaseline.eps}
\caption{Accuracy for the ar* data sets using within project data.}
\label{fig:accuBase}
\end{center}
\end{figure}
Training on data with equal priors is also supported by the precision versus recall plots, figure~\ref{fig:pvr-wos}
and figure~\ref{fig:pvr-ws}. When using these two measures, the prediction degraded substantially when using
the original data sets. In contrast, after subsampling, the prediction degraded less and in some cases was better
in the cross-project experiments compared to within project experiments.
\begin{figure}[btp]
\begin{center}
\includegraphics[width=.99\linewidth]{pics/pvr-wos.eps}
\caption{Precision versus recall without subsampling. The star inside a circle markers indicate the within project prediction.}
\label{fig:accuracy}
\end{center}
\end{figure}

\begin{figure}[btp]
\begin{center}
\includegraphics[width=.99\linewidth]{pics/pvr-ws.eps}
\caption{Precision versus recall with subsampling. The star inside a circle markers indicate the within project prediction.}
\label{fig:accuBase}
\end{center}
\end{figure}

\section{Conclusions}
Our goals for the next project are:
\begin{itemize}
\item{Implement attribute selection.}
\item{Implementing knn to be used in the cross-company experiments.}
\item{Run cross-company experiments.}
\item{Report results using cross-validation.}
\item{Try different subsampling, e.g. the Burak or the super-Burak filters.}
\item{Try different learners.}
\end{itemize}

% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{defects}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns

%\appendix

\end{document}
