Learning with disjoint sets introduces some caveats to data analysis. As seen in figure~\ref{fig:accuracy}, our baseline disjunctive MultiPipes outperforms both naive bayes and the original HyperPipes algorithm. However, our disjuntive learner doesn't exactly play fair, hedgings it's bets with multiple predicted classes. Note as well that when we use our centroid method for single classification, we fail to consistently beat naive bayes.

However, when disjunctive MultiPipes cheats, it does not hold back. As seen in the \% Ret column in figure~\ref{fig:performance}, on average Multipipes returns 67.3\% of all possible classes, with the average dataset consisting of 7 classes.
